{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "239e1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 1000\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV, StratifiedGroupKFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7727d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_ID</th>\n",
       "      <th>DISC/REP</th>\n",
       "      <th>indication</th>\n",
       "      <th>formal_status</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Consent</th>\n",
       "      <th>sessSeason</th>\n",
       "      <th>sessTime</th>\n",
       "      <th>Responder</th>\n",
       "      <th>Remitter</th>\n",
       "      <th>...</th>\n",
       "      <th>ever_used_cigarette</th>\n",
       "      <th>hours_since_last_cigarette</th>\n",
       "      <th>ever_used_coffee</th>\n",
       "      <th>hours_since_last_coffee</th>\n",
       "      <th>ever_used_beer</th>\n",
       "      <th>hours_since_last_beer</th>\n",
       "      <th>ever_used_drugs</th>\n",
       "      <th>hours_since_last_drugs</th>\n",
       "      <th>hours_since_last_meal</th>\n",
       "      <th>hours_since_last_sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-87999321</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>spring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-88000181</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-88000313</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-88000489</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-88000533</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participants_ID   DISC/REP indication formal_status   Dataset Consent  \\\n",
       "0    sub-87999321  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "1    sub-88000181  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "2    sub-88000313  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "3    sub-88000489  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "4    sub-88000533  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "\n",
       "  sessSeason sessTime  Responder  Remitter  ...  ever_used_cigarette  \\\n",
       "0     spring      NaN          1         1  ...                  0.0   \n",
       "1     summer      NaN          0         0  ...                  0.0   \n",
       "2     summer      NaN          1         1  ...                  1.0   \n",
       "3     summer      NaN          1         1  ...                  0.0   \n",
       "4     summer      NaN          1         1  ...                  1.0   \n",
       "\n",
       "   hours_since_last_cigarette  ever_used_coffee  hours_since_last_coffee  \\\n",
       "0                         NaN               0.0                      NaN   \n",
       "1                         NaN               1.0                      9.0   \n",
       "2                         9.0               1.0                      9.0   \n",
       "3                         NaN               1.0                      5.0   \n",
       "4                         8.0               1.0                      9.0   \n",
       "\n",
       "   ever_used_beer  hours_since_last_beer  ever_used_drugs  \\\n",
       "0             0.0                    NaN              1.0   \n",
       "1             1.0                   15.0              1.0   \n",
       "2             0.0                    NaN              1.0   \n",
       "3             1.0                   13.0              1.0   \n",
       "4             1.0                   13.0              1.0   \n",
       "\n",
       "   hours_since_last_drugs  hours_since_last_meal  hours_since_last_sleep  \n",
       "0                     0.0                    5.0                     7.0  \n",
       "1                     0.0                    3.0                     7.0  \n",
       "2                     0.0                    3.0                     9.0  \n",
       "3                     0.0                    5.0                     9.0  \n",
       "4                     0.0                    3.0                     5.0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/final_dataset_remitter.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2e6182e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participants_ID                 0\n",
      "n_oddb_FP                       0\n",
      "n_oddb_CN                       0\n",
      "n_oddb_FN                       0\n",
      "EO                              0\n",
      "EC                              0\n",
      "nrSessions                      0\n",
      "n_oddb_CP                       0\n",
      "gender                          0\n",
      "sessID                          0\n",
      "Responder                       0\n",
      "sessSeason                      0\n",
      "Consent                         0\n",
      "Dataset                         0\n",
      "DISC/REP                        0\n",
      "Remitter                        0\n",
      "ever_used_cigarette             1\n",
      "ever_used_coffee                1\n",
      "hearing                         1\n",
      "vision                          1\n",
      "well                            1\n",
      "education                       1\n",
      "ever_used_beer                  1\n",
      "ever_used_drugs                 1\n",
      "hours_since_last_meal           1\n",
      "hours_since_last_sleep          1\n",
      "indication                      1\n",
      "age                             1\n",
      "avg_rt_oddb_CP                  4\n",
      "neoFFI_q11                     10\n",
      "neoFFI_q44                     10\n",
      "neoFFI_q45                     10\n",
      "neoFFI_q46                     10\n",
      "neoFFI_q47                     10\n",
      "neoFFI_q48                     10\n",
      "neoFFI_q49                     10\n",
      "neoFFI_q50                     10\n",
      "neoFFI_q51                     10\n",
      "neoFFI_q52                     10\n",
      "neoFFI_q53                     10\n",
      "neoFFI_q10                     10\n",
      "neoFFI_q55                     10\n",
      "neoFFI_q57                     10\n",
      "neoFFI_q43                     10\n",
      "neoFFI_q58                     10\n",
      "neoFFI_q59                     10\n",
      "neoFFI_q60                     10\n",
      "neoFFI_q8                      10\n",
      "neoFFI_q7                      10\n",
      "neoFFI_q6                      10\n",
      "neoFFI_q5                      10\n",
      "neoFFI_q4                      10\n",
      "neoFFI_q3                      10\n",
      "neoFFI_q2                      10\n",
      "neoFFI_q1                      10\n",
      "neoFFI_q56                     10\n",
      "neoFFI_q42                     10\n",
      "neoFFI_q54                     10\n",
      "neoFFI_q40                     10\n",
      "neoFFI_q12                     10\n",
      "neoFFI_q13                     10\n",
      "neoFFI_q14                     10\n",
      "neoFFI_q15                     10\n",
      "neoFFI_q16                     10\n",
      "neoFFI_q17                     10\n",
      "neoFFI_q9                      10\n",
      "neoFFI_q18                     10\n",
      "neoFFI_q19                     10\n",
      "neoFFI_q20                     10\n",
      "neoFFI_q21                     10\n",
      "neoFFI_q22                     10\n",
      "neoFFI_q23                     10\n",
      "neoFFI_q24                     10\n",
      "neoFFI_q41                     10\n",
      "neoFFI_q26                     10\n",
      "neoFFI_q36                     10\n",
      "neoFFI_q35                     10\n",
      "neoFFI_q34                     10\n",
      "neoFFI_q33                     10\n",
      "neoFFI_q38                     10\n",
      "neoFFI_q37                     10\n",
      "neoFFI_q25                     10\n",
      "neoFFI_q31                     10\n",
      "neoFFI_q30                     10\n",
      "neoFFI_q29                     10\n",
      "neoFFI_q39                     10\n",
      "neoFFI_q28                     10\n",
      "neoFFI_q27                     10\n",
      "neoFFI_q32                     10\n",
      "formal_status                  21\n",
      "BDI_pre                        29\n",
      "BDI_post                       32\n",
      "hours_since_last_coffee        62\n",
      "n_wm_FP                        67\n",
      "n_wm_FN                        67\n",
      "n_wm_CN                        67\n",
      "n_wm_CP                        67\n",
      "rTMS_protocol                  68\n",
      "avg_rt_oddb_FP                118\n",
      "hours_since_last_cigarette    152\n",
      "hours_since_last_beer         157\n",
      "ADHD_pre_Hyp_leading          160\n",
      "ADHD_pre_Att_leading          160\n",
      "ADHD_post_Att_leading         160\n",
      "ADHD_post_Hyp_leading         160\n",
      "NF_protocol                   160\n",
      "hours_since_last_drugs        166\n",
      "YBOCS_post                    198\n",
      "YBOCS_pre                     198\n",
      "weight                        222\n",
      "height                        222\n",
      "sessTime                      225\n",
      "avg_rt_wm_CP                  226\n",
      "avg_rt_wm_FP                  226\n",
      "dtype: int64\n",
      "Row missing age: Index([36], dtype='int64')\n",
      "Row missing indication: Index([192], dtype='int64')\n",
      "Row missing hearing: Index([45], dtype='int64')\n",
      "Row missing well: Index([45], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "missing_counts = df.isnull().sum()\n",
    "missing_counts_sorted = missing_counts.sort_values() # sort\n",
    "print(missing_counts_sorted)\n",
    "\n",
    "print(\"Row missing age:\", df[df[\"age\"].isna()].index)\n",
    "print(\"Row missing indication:\", df[df[\"indication\"].isna()].index)\n",
    "print(\"Row missing hearing:\", df[df[\"hearing\"].isna()].index)\n",
    "print(\"Row missing well:\", df[df[\"well\"].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a0e7e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    participants_ID   DISC/REP indication formal_status   Dataset Consent  \\\n",
      "12     sub-88006161  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "13     sub-88006161  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "18     sub-88009901  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "19     sub-88009901  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "24     sub-88010981  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "25     sub-88010981  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "29     sub-88012461  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "30     sub-88012461  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "35     sub-88015117  DISCOVERY       ADHD          ADHD   ADHD_NF     YES   \n",
      "36     sub-88015117  DISCOVERY       ADHD           NaN   ADHD_NF     YES   \n",
      "38     sub-88017409  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "39     sub-88017409  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "43     sub-88020065  DISCOVERY       ADHD           NaN   ADHD_NF     YES   \n",
      "44     sub-88020065  DISCOVERY       ADHD           NaN   ADHD_NF     YES   \n",
      "51     sub-88021365  DISCOVERY       ADHD           NaN   ADHD_NF     YES   \n",
      "52     sub-88021365  DISCOVERY       ADHD           NaN   ADHD_NF     YES   \n",
      "53     sub-88022089  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "54     sub-88022089  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "58     sub-88023125  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "59     sub-88023125  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "62     sub-88024205  DISCOVERY       ADHD          ADHD   ADHD_NF     YES   \n",
      "63     sub-88024205  DISCOVERY       ADHD          ADHD   ADHD_NF     YES   \n",
      "71     sub-88025785  DISCOVERY       ADHD           NaN   ADHD_NF     YES   \n",
      "72     sub-88025785  DISCOVERY       ADHD           NaN   ADHD_NF     YES   \n",
      "130    sub-88045713  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "131    sub-88045713  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
      "139    sub-88047649  DISCOVERY        OCD           OCD       OCD     YES   \n",
      "140    sub-88047649  DISCOVERY        OCD           OCD       OCD     YES   \n",
      "142    sub-88048193  DISCOVERY        OCD           OCD       OCD     YES   \n",
      "143    sub-88048193  DISCOVERY        OCD           OCD       OCD     YES   \n",
      "\n",
      "    sessSeason sessTime  Responder  Remitter  ...  ever_used_cigarette  \\\n",
      "12      winter      NaN          1         1  ...                  0.0   \n",
      "13      summer      NaN          1         1  ...                  0.0   \n",
      "18      spring      NaN          1         1  ...                  1.0   \n",
      "19      winter      NaN          1         1  ...                  1.0   \n",
      "24      spring      NaN          1         1  ...                  0.0   \n",
      "25        fall      NaN          1         1  ...                  0.0   \n",
      "29      summer      NaN          1         1  ...                  0.0   \n",
      "30        fall      NaN          1         1  ...                  0.0   \n",
      "35      summer      NaN          1         1  ...                  0.0   \n",
      "36      summer      NaN          1         1  ...                  0.0   \n",
      "38        fall      NaN          1         1  ...                  0.0   \n",
      "39      spring      NaN          1         1  ...                  0.0   \n",
      "43      winter      NaN          1         1  ...                  0.0   \n",
      "44      summer      NaN          1         1  ...                  0.0   \n",
      "51      spring      NaN          1         1  ...                  1.0   \n",
      "52        fall      NaN          1         1  ...                  1.0   \n",
      "53      spring      NaN          1         1  ...                  0.0   \n",
      "54      summer      NaN          1         1  ...                  0.0   \n",
      "58      spring      NaN          1         1  ...                  0.0   \n",
      "59        fall      NaN          1         1  ...                  0.0   \n",
      "62      summer      NaN          1         1  ...                  0.0   \n",
      "63      summer      NaN          1         1  ...                  0.0   \n",
      "71      summer      NaN          1         1  ...                  1.0   \n",
      "72      spring      NaN          1         1  ...                  1.0   \n",
      "130       fall      NaN          1         1  ...                  0.0   \n",
      "131     summer      NaN          1         1  ...                  0.0   \n",
      "139     summer      NaN          1         1  ...                  1.0   \n",
      "140     summer      NaN          1         1  ...                  1.0   \n",
      "142     summer      NaN          1         0  ...                  0.0   \n",
      "143     winter      NaN          1         0  ...                  0.0   \n",
      "\n",
      "     hours_since_last_cigarette  ever_used_coffee  hours_since_last_coffee  \\\n",
      "12                          NaN               1.0                      9.0   \n",
      "13                          NaN               0.0                      NaN   \n",
      "18                          5.0               1.0                      5.0   \n",
      "19                          9.0               1.0                      9.0   \n",
      "24                          NaN               0.0                      NaN   \n",
      "25                          NaN               0.0                      NaN   \n",
      "29                          NaN               0.0                      NaN   \n",
      "30                          NaN               0.0                      NaN   \n",
      "35                          NaN               0.0                      NaN   \n",
      "36                          NaN               1.0                      9.0   \n",
      "38                          NaN               0.0                      NaN   \n",
      "39                          NaN               1.0                      9.0   \n",
      "43                          NaN               0.0                      NaN   \n",
      "44                          NaN               0.0                      NaN   \n",
      "51                          3.0               1.0                      4.0   \n",
      "52                          3.0               1.0                      3.0   \n",
      "53                          NaN               1.0                      9.0   \n",
      "54                          NaN               1.0                      8.0   \n",
      "58                          NaN               1.0                      4.0   \n",
      "59                          NaN               1.0                      6.0   \n",
      "62                          NaN               0.0                      NaN   \n",
      "63                          NaN               0.0                      NaN   \n",
      "71                          9.0               1.0                      9.0   \n",
      "72                          3.0               1.0                      9.0   \n",
      "130                         NaN               0.0                      NaN   \n",
      "131                         NaN               0.0                      NaN   \n",
      "139                         3.0               1.0                      4.0   \n",
      "140                         9.0               1.0                      3.0   \n",
      "142                         NaN               1.0                      4.0   \n",
      "143                         NaN               1.0                      5.0   \n",
      "\n",
      "     ever_used_beer  hours_since_last_beer  ever_used_drugs  \\\n",
      "12              0.0                    NaN              1.0   \n",
      "13              0.0                    NaN              1.0   \n",
      "18              0.0                    NaN              1.0   \n",
      "19              0.0                    NaN              0.0   \n",
      "24              0.0                    NaN              1.0   \n",
      "25              0.0                    NaN              1.0   \n",
      "29              0.0                    NaN              1.0   \n",
      "30              0.0                    NaN              1.0   \n",
      "35              0.0                    NaN              1.0   \n",
      "36              0.0                    NaN              0.0   \n",
      "38              0.0                    NaN              1.0   \n",
      "39              0.0                    NaN              0.0   \n",
      "43              0.0                    NaN              0.0   \n",
      "44              0.0                    NaN              0.0   \n",
      "51              0.0                    NaN              0.0   \n",
      "52              0.0                    NaN              0.0   \n",
      "53              0.0                    NaN              0.0   \n",
      "54              0.0                    NaN              0.0   \n",
      "58              1.0                   15.0              0.0   \n",
      "59              1.0                   15.0              0.0   \n",
      "62              0.0                    NaN              0.0   \n",
      "63              0.0                    NaN              0.0   \n",
      "71              0.0                    NaN              0.0   \n",
      "72              0.0                    NaN              0.0   \n",
      "130             0.0                    NaN              0.0   \n",
      "131             0.0                    NaN              0.0   \n",
      "139             0.0                    NaN              0.0   \n",
      "140             0.0                    NaN              0.0   \n",
      "142             1.0                   13.0              0.0   \n",
      "143             1.0                   15.0              0.0   \n",
      "\n",
      "     hours_since_last_drugs  hours_since_last_meal  hours_since_last_sleep  \n",
      "12                      0.0                    4.0                     5.0  \n",
      "13                      0.0                    2.0                     7.0  \n",
      "18                      0.0                    3.0                     5.0  \n",
      "19                      NaN                    9.0                     7.0  \n",
      "24                      0.0                    1.0                     5.0  \n",
      "25                      0.0                    4.0                     9.0  \n",
      "29                      0.0                    2.0                     9.0  \n",
      "30                      0.0                    2.0                     9.0  \n",
      "35                      0.0                    1.0                     9.0  \n",
      "36                      NaN                    1.0                     7.0  \n",
      "38                      0.0                    2.0                     5.0  \n",
      "39                      NaN                    1.0                     5.0  \n",
      "43                      NaN                    5.0                     7.0  \n",
      "44                      NaN                    2.0                     7.0  \n",
      "51                      NaN                    3.0                     9.0  \n",
      "52                      NaN                    3.0                     7.0  \n",
      "53                      NaN                    6.0                     7.0  \n",
      "54                      NaN                    2.0                     9.0  \n",
      "58                      NaN                    4.0                     7.0  \n",
      "59                      NaN                    3.0                     7.0  \n",
      "62                      NaN                    4.0                     9.0  \n",
      "63                      NaN                    3.0                     9.0  \n",
      "71                      NaN                    3.0                     5.0  \n",
      "72                      NaN                    2.0                     7.0  \n",
      "130                     NaN                    3.0                     5.0  \n",
      "131                     NaN                    2.0                     7.0  \n",
      "139                     NaN                    3.0                     3.0  \n",
      "140                     NaN                    2.0                     7.0  \n",
      "142                     NaN                    1.0                     7.0  \n",
      "143                     NaN                    1.0                     9.0  \n",
      "\n",
      "[30 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "duplicate_ids = df[\"participants_ID\"].value_counts()\n",
    "duplicate_ids = duplicate_ids[duplicate_ids > 1].index\n",
    "\n",
    "print(df[df[\"participants_ID\"].isin(duplicate_ids)])\n",
    "\n",
    "# TO DO: may need to handle group structure in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9342bc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non-predictive columns\n",
    "participants_ids = df['participants_ID']\n",
    "df = df.drop(columns=['participants_ID','Dataset','sessID','sessSeason','nrSessions','sessTime'])\n",
    "df = df.drop(columns=['Consent','DISC/REP','EC','EO']) # one unique val across all participants\n",
    "df = df.drop(columns=['vision','hearing']) # only has unique vals 0 or missing\n",
    "# remove columns that would cause data leakage\n",
    "df = df.drop(columns=['Responder','BDI_post','YBOCS_post','ADHD_post_Att_leading','ADHD_post_Hyp_leading'])\n",
    "# pull out target variable: Remitter\n",
    "y = df['Remitter']\n",
    "df = df.drop(columns=['Remitter'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0ae49f",
   "metadata": {},
   "source": [
    "## First try: use columns with few missing values (<=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ad491314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 16)\n",
      "Index(['indication', 'age', 'gender', 'avg_rt_oddb_CP', 'n_oddb_CP',\n",
      "       'n_oddb_FP', 'n_oddb_CN', 'n_oddb_FN', 'education', 'well',\n",
      "       'ever_used_cigarette', 'ever_used_coffee', 'ever_used_beer',\n",
      "       'ever_used_drugs', 'hours_since_last_meal', 'hours_since_last_sleep'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>indication</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>avg_rt_oddb_CP</th>\n",
       "      <th>n_oddb_CP</th>\n",
       "      <th>n_oddb_FP</th>\n",
       "      <th>n_oddb_CN</th>\n",
       "      <th>n_oddb_FN</th>\n",
       "      <th>education</th>\n",
       "      <th>well</th>\n",
       "      <th>ever_used_cigarette</th>\n",
       "      <th>ever_used_coffee</th>\n",
       "      <th>ever_used_beer</th>\n",
       "      <th>ever_used_drugs</th>\n",
       "      <th>hours_since_last_meal</th>\n",
       "      <th>hours_since_last_sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MDD</td>\n",
       "      <td>49.66</td>\n",
       "      <td>male</td>\n",
       "      <td>0.261</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MDD</td>\n",
       "      <td>45.99</td>\n",
       "      <td>female</td>\n",
       "      <td>0.306</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MDD</td>\n",
       "      <td>35.38</td>\n",
       "      <td>female</td>\n",
       "      <td>0.291</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MDD</td>\n",
       "      <td>42.36</td>\n",
       "      <td>male</td>\n",
       "      <td>0.319</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MDD</td>\n",
       "      <td>45.14</td>\n",
       "      <td>female</td>\n",
       "      <td>0.458</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  indication    age  gender  avg_rt_oddb_CP  n_oddb_CP  n_oddb_FP  n_oddb_CN  \\\n",
       "0        MDD  49.66    male           0.261         60          0        280   \n",
       "1        MDD  45.99  female           0.306         60          0        280   \n",
       "2        MDD  35.38  female           0.291         60          0        280   \n",
       "3        MDD  42.36    male           0.319         59          0        280   \n",
       "4        MDD  45.14  female           0.458         60          0        280   \n",
       "\n",
       "   n_oddb_FN  education  well ever_used_cigarette ever_used_coffee  \\\n",
       "0          0       18.0   1.0                  no               no   \n",
       "1          0       11.0  -2.0                  no              yes   \n",
       "2          0       17.0   1.0                 yes              yes   \n",
       "3          1       18.0   1.0                  no              yes   \n",
       "4          0       17.0   1.0                 yes              yes   \n",
       "\n",
       "  ever_used_beer ever_used_drugs  hours_since_last_meal  \\\n",
       "0             no             yes                    5.0   \n",
       "1            yes             yes                    3.0   \n",
       "2             no             yes                    3.0   \n",
       "3            yes             yes                    5.0   \n",
       "4            yes             yes                    3.0   \n",
       "\n",
       "   hours_since_last_sleep  \n",
       "0                     7.0  \n",
       "1                     7.0  \n",
       "2                     9.0  \n",
       "3                     9.0  \n",
       "4                     5.0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_few_missing = df.loc[:, df.isna().sum() <= 5]\n",
    "X_few_missing = X_few_missing.copy()\n",
    "\n",
    "# binary vars float --> str\n",
    "X_few_missing['gender'] = X_few_missing['gender'].map({1.0: 'male', 0.0: 'female'})\n",
    "binary_cols = ['ever_used_cigarette', 'ever_used_coffee', 'ever_used_beer', 'ever_used_drugs']\n",
    "for col in binary_cols:\n",
    "    X_few_missing[col] = X_few_missing[col].map({1.0: 'yes', 0.0: 'no'})\n",
    "\n",
    "print(X_few_missing.shape)\n",
    "print(X_few_missing.columns)\n",
    "X_few_missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5660bcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct preprocesser\n",
    "# decide which encoder to use on each feature\n",
    "onehot_ftrs = ['indication','gender','ever_used_cigarette','ever_used_coffee','ever_used_beer','ever_used_drugs']\n",
    "ordinal_ftrs = ['well']\n",
    "ordinal_cats = [[-2, -1, 0, 1, 2, 3]]\n",
    "std_ftrs = ['age','avg_rt_oddb_CP','n_oddb_CP','n_oddb_FP','n_oddb_CN','n_oddb_FN','education','hours_since_last_meal','hours_since_last_sleep']\n",
    "\n",
    "# one hot pipeline = just fill nan with 'missing'\n",
    "onehot_transformer = Pipeline(steps=[\n",
    "    ('imputer0', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# ordinal pipeline\n",
    "ordinal_transformer = Pipeline(steps=[\n",
    "    ('imputer1', SimpleImputer(strategy='constant',fill_value=1)), # fills missing values with 1 = normal\n",
    "    ('ordinal', OrdinalEncoder(categories = ordinal_cats)),\n",
    "    ('scaler', StandardScaler()) \n",
    "])\n",
    "\n",
    "# numeric pipeline with imputation + scaling\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='median')),  # fills missing values with median\n",
    "    ('scaler', StandardScaler())                    # scales features\n",
    "])\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', onehot_transformer, onehot_ftrs), \n",
    "        ('ord', ordinal_transformer, ordinal_ftrs),\n",
    "        ('std', numeric_transformer, std_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "985e897a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(181, 16)\n",
      "(45, 16)\n"
     ]
    }
   ],
   "source": [
    "# outer split - separate holdout test set\n",
    "# gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "# train_val_idx, test_idx = next(gss.split(X_few_missing, y, groups=participants_ids))\n",
    "\n",
    "# X_train_val = X_few_missing.iloc[train_val_idx]\n",
    "# y_train_val = y.iloc[train_val_idx]\n",
    "# groups_train_val = participants_ids.iloc[train_val_idx]\n",
    "\n",
    "# X_test = X_few_missing.iloc[test_idx]\n",
    "# y_test = y.iloc[test_idx]\n",
    "\n",
    "# print(X_train_val.shape)\n",
    "# print(X_test.shape)\n",
    "\n",
    "outer_split = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=42) # Outer split: split test and other\n",
    "\n",
    "for train_val_idx, test_idx in outer_split.split(X_few_missing, y, groups=participants_ids):\n",
    "    break \n",
    "\n",
    "X_train_val = X_few_missing.iloc[train_val_idx]\n",
    "y_train_val = y.iloc[train_val_idx]\n",
    "groups_train_val = participants_ids.iloc[train_val_idx]\n",
    "\n",
    "X_test = X_few_missing.iloc[test_idx]\n",
    "y_test = y.iloc[test_idx]\n",
    "\n",
    "print(X_train_val.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a0f6cf13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "X_train shape: (134, 16)\n",
      "X_val shape: (47, 16)\n",
      "Fold 2\n",
      "X_train shape: (135, 16)\n",
      "X_val shape: (46, 16)\n",
      "Fold 3\n",
      "X_train shape: (136, 16)\n",
      "X_val shape: (45, 16)\n",
      "Fold 4\n",
      "X_train shape: (138, 16)\n",
      "X_val shape: (43, 16)\n"
     ]
    }
   ],
   "source": [
    "# split data (groupkfold?)\n",
    "# n_splits = 5\n",
    "# gkf = GroupKFold(n_splits=n_splits)\n",
    "# ids_train_val = participants_ids.iloc[train_val_idx]\n",
    "\n",
    "# for fold, (train_idx, val_idx) in enumerate(gkf.split(X_train_val, y_train_val, groups=ids_train_val)):\n",
    "#     print(f\"Fold {fold+1}\")\n",
    "#     X_train, X_val = X_train_val.iloc[train_idx], X_train_val.iloc[val_idx]\n",
    "#     y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "#     print(\"X_train shape:\", X_train.shape)\n",
    "#     print(\"X_val shape:\", X_val.shape)\n",
    "\n",
    "inner_split = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "ids_train_val = participants_ids.iloc[train_val_idx]\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(inner_split.split(X_train_val, y_train_val, groups=ids_train_val)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_train, X_val = X_train_val.iloc[train_idx], X_train_val.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_val shape:\", X_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6f4e29d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing...\n",
      "X train: (138, 16)\n",
      "X val: (43, 16)\n",
      "X test: (45, 16) \n",
      "\n",
      "['indication_ADHD', 'indication_ADHD/OCD', 'indication_MDD', 'indication_MDD/BIPOLAR', 'indication_MDD/OCD', 'indication_OCD', 'indication_OCD/ASD', 'indication_missing', 'gender_female', 'gender_male', 'ever_used_cigarette_no', 'ever_used_cigarette_yes', 'ever_used_coffee_no', 'ever_used_coffee_yes', 'ever_used_beer_no', 'ever_used_beer_yes', 'ever_used_drugs_no', 'ever_used_drugs_yes', 'well', 'age', 'avg_rt_oddb_CP', 'n_oddb_CP', 'n_oddb_FP', 'n_oddb_CN', 'n_oddb_FN', 'education', 'hours_since_last_meal', 'hours_since_last_sleep']\n",
      "After preprocessing...\n",
      "X train: (138, 28)\n",
      "X val: (43, 28)\n",
      "X test: (45, 28)\n"
     ]
    }
   ],
   "source": [
    "# try preprocessor on the last fold\n",
    "print(\"Before preprocessing...\")\n",
    "print(\"X train:\", X_train.shape)\n",
    "print(\"X val:\", X_val.shape)\n",
    "print(\"X test:\", X_test.shape, \"\\n\")\n",
    "\n",
    "X_train_prep = clf.fit_transform(X_train)\n",
    "\n",
    "# relabel the columns after transformation\n",
    "onehot_feature_names = clf.named_steps['preprocessor'].named_transformers_['onehot'].get_feature_names_out()\n",
    "new_feature_names = list(onehot_feature_names) + ordinal_ftrs + std_ftrs\n",
    "print(new_feature_names)\n",
    "\n",
    "X_train_prep = pd.DataFrame(X_train_prep, columns=new_feature_names)\n",
    "X_val_prep = pd.DataFrame(clf.transform(X_val), columns=new_feature_names)\n",
    "X_test_prep = pd.DataFrame(clf.transform(X_test), columns=new_feature_names)\n",
    "\n",
    "# print number of data points after preprocessing\n",
    "print(\"After preprocessing...\")\n",
    "print(\"X train:\", X_train_prep.shape)\n",
    "print(\"X val:\", X_val_prep.shape)\n",
    "print(\"X test:\", X_test_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a20e6d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.5581395348837209\n",
      "Accuracy on training set: 0.6739130434782609\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='saga', max_iter=100000000)\n",
    "log_reg.fit(X_train_prep, y_train)\n",
    "y_pred_val = log_reg.predict(X_val_prep)\n",
    "y_pred_train = log_reg.predict(X_train_prep)\n",
    "print(\"Accuracy on validation set:\", accuracy_score(y_val,y_pred_val))\n",
    "print(\"Accuracy on training set:\", accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7e80ecf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.5581395348837209\n",
      "Accuracy on training set: 0.6884057971014492\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(kernel='rbf', C=1.0, gamma='scale')\n",
    "svc.fit(X_train_prep, y_train)\n",
    "y_pred_val = svc.predict(X_val_prep)\n",
    "y_pred_train = svc.predict(X_train_prep)\n",
    "print(\"Accuracy on validation set:\", accuracy_score(y_val,y_pred_val))\n",
    "print(\"Accuracy on training set:\", accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "98279c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLpipe_SGKFold(X, y, group_ids, preprocessor, ML_algo, param_grid, model_name, eval_metric):\n",
    "    '''\n",
    "    Pipeline with:\n",
    "        Splitting method -- StratifiedGroupKFold\n",
    "        Evaluation metric -- Depends on input\n",
    "    '''\n",
    "\n",
    "    test_scores = []\n",
    "    best_models = []\n",
    "\n",
    "    num_states = 10\n",
    "\n",
    "    for i in range(num_states):\n",
    "        # Define random state\n",
    "        random_state = 29*i\n",
    "        print(f\"---Running random state {random_state}---\")\n",
    "\n",
    "        # ---SPLIT---\n",
    "        outer_split = StratifiedGroupKFold(n_splits=5, shuffle=True, random_state=random_state) # Outer split: split test and other\n",
    "\n",
    "        for other_idx, test_idx in outer_split.split(X, y, groups=group_ids):\n",
    "            break # Break after the first split to separate out the test set for this state\n",
    "        \n",
    "        X_other = X.iloc[other_idx]\n",
    "        y_other = y.iloc[other_idx]\n",
    "        subject_ids_other = group_ids.iloc[other_idx] \n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_test = y.iloc[test_idx]\n",
    "\n",
    "        kf = StratifiedGroupKFold(n_splits=4, shuffle=True, random_state=random_state) # Inner split: 4 fold CV\n",
    "\n",
    "        # ---PREPROCESS---\n",
    "        # Main preprocessor is fed into function in \"preprocessor\"\n",
    "        final_scaler = StandardScaler()\n",
    "\n",
    "        # ---CONSTRUCT PIPELINE & GRID SEARCH---\n",
    "        pipeline = make_pipeline(preprocessor, ML_algo)\n",
    "\n",
    "        if eval_metric == \"accuracy\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='accuracy', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        elif eval_metric == \"precision\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='precision_macro', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        elif eval_metric == \"f1_macro\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='f1_macro', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        elif eval_metric == \"f1_weighted\":\n",
    "            grid = GridSearchCV(pipeline, param_grid=param_grid, cv=kf, scoring='f1_weighted', return_train_score=True, n_jobs=-1, verbose=True)\n",
    "        else:\n",
    "            raise ValueError(\"Evaluation metric not handled in this pipeline.\")\n",
    "        \n",
    "        grid.fit(X_other, y_other, groups=subject_ids_other)\n",
    "\n",
    "        results = pd.DataFrame(grid.cv_results_)\n",
    "        # print(\"\\nGrid search results:\\n\", results)\n",
    "\n",
    "        # ---SAVE BEST MODEL PER RANDOM STATE PER MODEL---\n",
    "        best_model = grid.best_estimator_\n",
    "        best_models.append(best_model)\n",
    "        print('Best model parameters:', grid.best_params_)\n",
    "        y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "        if eval_metric == \"accuracy\":\n",
    "            best_test_score = accuracy_score(y_test, y_test_pred)\n",
    "        elif eval_metric == \"precision\":\n",
    "            best_test_score = precision_score(y_test, y_test_pred, average=\"macro\")\n",
    "        elif eval_metric == \"f1_macro\":\n",
    "            best_test_score = f1_score(y_test, y_test_pred, average=\"macro\")\n",
    "        elif eval_metric == \"f1_weighted\":\n",
    "            best_test_score = f1_score(y_test, y_test_pred, average=\"weighted\")\n",
    "        else:\n",
    "            raise ValueError(\"Evaluation metric not handled in this pipeline.\")\n",
    "            \n",
    "        test_scores.append(best_test_score)\n",
    "        print(f\"Test score for random state {29*i}: {best_test_score:.4f}\")\n",
    "        \n",
    "    # ---SAVE ALL BEST MODELS AND TEST SCORES PER MODEL IN RESULTS---\n",
    "    file_path = os.path.join('../results/', f'{model_name}_{eval_metric}_remitter.save')\n",
    "    with open(file_path, 'wb') as file:\n",
    "        pickle.dump((best_models, test_scores), file)\n",
    "\n",
    "    return test_scores, best_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7324adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---Running random state 0---\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 0: 0.5833\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 29: 0.5745\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 58: 0.6222\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 87: 0.6000\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 116: 0.6047\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 145: 0.5435\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 174: 0.6667\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 203: 0.6383\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 261: 0.5870\n"
     ]
    }
   ],
   "source": [
    "# test pipeline on simple logistic regression model first\n",
    "log_reg = LogisticRegression(solver='saga', max_iter=100000000)\n",
    "param_grid = {} \n",
    "log_reg_test_scores, log_reg_best_models = MLpipe_SGKFold(X_few_missing, y, participants_ids, preprocessor, log_reg, param_grid, \"Test_SimpleLogisticRegression\", \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "527150a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model algorithms and parameter grids\n",
    "models = {\n",
    "    'SimpleLogisticRegression': (\n",
    "        LogisticRegression(solver='saga', max_iter=1000000), {} \n",
    "    ),\n",
    "    'L1LogisticRegression': (\n",
    "        LogisticRegression(penalty='l1', solver='saga', max_iter=1000000),\n",
    "        {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    ),\n",
    "    'L2LogisticRegression': (\n",
    "        LogisticRegression(penalty='l2', solver='saga', max_iter=1000000),\n",
    "        {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
    "    ),\n",
    "    'ElasticNet': (\n",
    "        LogisticRegression(penalty='elasticnet', solver='saga', max_iter=100000000),\n",
    "        {'logisticregression__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "         'logisticregression__l1_ratio': [0.001, 0.01, 0.1, 1]}\n",
    "    ),\n",
    "    'RandomForestClassifier': (\n",
    "        RandomForestClassifier(random_state=42),\n",
    "        {'randomforestclassifier__n_estimators': [100],\n",
    "         'randomforestclassifier__max_depth': [1, 3, 5, 10, 20, 100],\n",
    "         'randomforestclassifier__max_features': [0.25, 0.5, 0.75, 1.0, None]}\n",
    "    ),\n",
    "    'SupportVectorClassifier': (\n",
    "        SVC(probability=True),\n",
    "        {'svc__C': [1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "         'svc__gamma': [1e-5, 1e-3, 1e-1, 1e1, 1e3, 1e5]}\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9960738f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SimpleLogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 0: 0.5833\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 29: 0.5745\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 58: 0.6222\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 87: 0.6000\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 116: 0.6047\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 145: 0.5435\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 174: 0.6667\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 203: 0.6383\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 261: 0.5870\n",
      "Test Accuracy Scores: [0.5833333333333334, 0.574468085106383, 0.6222222222222222, 0.6, 0.6046511627906976, 0.5434782608695652, 0.6666666666666666, 0.6382978723404256, 0.625, 0.5869565217391305]\n",
      "Mean Test Accuracy: 0.6045\n",
      "Std Dev of Test Accuracy: 0.0334\n",
      "\n",
      "Training L1LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 0: 0.5625\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 29: 0.5957\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 87: 0.6222\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.01}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 145: 0.4783\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 174: 0.5333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 203: 0.6170\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 232: 0.6042\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 261: 0.5652\n",
      "Test Accuracy Scores: [0.5625, 0.5957446808510638, 0.4444444444444444, 0.6222222222222222, 0.4883720930232558, 0.4782608695652174, 0.5333333333333333, 0.6170212765957447, 0.6041666666666666, 0.5652173913043478]\n",
      "Mean Test Accuracy: 0.5511\n",
      "Std Dev of Test Accuracy: 0.0596\n",
      "\n",
      "Training L2LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 0: 0.5625\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 29: 0.5745\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 87: 0.5778\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 145: 0.5435\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 174: 0.5333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 203: 0.6170\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 232: 0.6042\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.1}\n",
      "Test score for random state 261: 0.5000\n",
      "Test Accuracy Scores: [0.5625, 0.574468085106383, 0.4444444444444444, 0.5777777777777777, 0.4883720930232558, 0.5434782608695652, 0.5333333333333333, 0.6170212765957447, 0.6041666666666666, 0.5]\n",
      "Mean Test Accuracy: 0.5446\n",
      "Std Dev of Test Accuracy: 0.0514\n",
      "\n",
      "Training ElasticNet...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 0: 0.5625\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 29: 0.5745\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 10, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 87: 0.5778\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 145: 0.5435\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 174: 0.5333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 203: 0.6170\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 100, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 232: 0.6042\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 261: 0.5652\n",
      "Test Accuracy Scores: [0.5625, 0.574468085106383, 0.4444444444444444, 0.5777777777777777, 0.4883720930232558, 0.5434782608695652, 0.5333333333333333, 0.6170212765957447, 0.6041666666666666, 0.5652173913043478]\n",
      "Mean Test Accuracy: 0.5511\n",
      "Std Dev of Test Accuracy: 0.0494\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 20, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 0: 0.5833\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 29: 0.5319\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 87: 0.6444\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 116: 0.5581\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 145: 0.4565\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 10, 'randomforestclassifier__max_features': 1.0, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 174: 0.6222\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 1.0, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 203: 0.6383\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 261: 0.5870\n",
      "Test Accuracy Scores: [0.5833333333333334, 0.5319148936170213, 0.4444444444444444, 0.6444444444444445, 0.5581395348837209, 0.45652173913043476, 0.6222222222222222, 0.6382978723404256, 0.625, 0.5869565217391305]\n",
      "Mean Test Accuracy: 0.5691\n",
      "Std Dev of Test Accuracy: 0.0683\n",
      "\n",
      "Training SupportVectorClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1.0, 'svc__gamma': 0.1}\n",
      "Test score for random state 0: 0.5208\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 29: 0.5532\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 58: 0.4667\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 87: 0.6222\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 0.01, 'svc__gamma': 1e-05}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 145: 0.5652\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 0.01, 'svc__gamma': 1e-05}\n",
      "Test score for random state 174: 0.5333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 203: 0.5957\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 0.001}\n",
      "Test score for random state 261: 0.5652\n",
      "Test Accuracy Scores: [0.5208333333333334, 0.5531914893617021, 0.4666666666666667, 0.6222222222222222, 0.4883720930232558, 0.5652173913043478, 0.5333333333333333, 0.5957446808510638, 0.625, 0.5652173913043478]\n",
      "Mean Test Accuracy: 0.5536\n",
      "Std Dev of Test Accuracy: 0.0501\n",
      "\n",
      "Summary of Results:\n",
      "SimpleLogisticRegression: Mean Accuracy = 0.6045, Std Dev = 0.0334\n",
      "L1LogisticRegression: Mean Accuracy = 0.5511, Std Dev = 0.0596\n",
      "L2LogisticRegression: Mean Accuracy = 0.5446, Std Dev = 0.0514\n",
      "ElasticNet: Mean Accuracy = 0.5511, Std Dev = 0.0494\n",
      "RandomForestClassifier: Mean Accuracy = 0.5691, Std Dev = 0.0683\n",
      "SupportVectorClassifier: Mean Accuracy = 0.5536, Std Dev = 0.0501\n"
     ]
    }
   ],
   "source": [
    "# evaluation metric = accuracy\n",
    "summary_acc = {}\n",
    "for model_name, (algo, param_grid) in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    test_scores, best_models = MLpipe_SGKFold(X_few_missing, y, participants_ids, preprocessor, algo, param_grid, model_name, \"accuracy\")\n",
    "    mean_score = np.mean(test_scores)\n",
    "    stddev_score = np.std(test_scores)\n",
    "    print(\"Test Accuracy Scores:\", test_scores)\n",
    "    print(f\"Mean Test Accuracy: {mean_score:.4f}\")\n",
    "    print(f\"Std Dev of Test Accuracy: {stddev_score:.4f}\")\n",
    "    summary_acc[model_name] = (mean_score, stddev_score)\n",
    "\n",
    "# display the summary\n",
    "print(\"\\nSummary of Results:\")\n",
    "for model_name, (mean_score, stddev_score) in summary_acc.items():\n",
    "    print(f\"{model_name}: Mean Accuracy = {mean_score:.4f}, Std Dev = {stddev_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ac1afe09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Results:\n",
    "# SimpleLogisticRegression: Mean Accuracy = 0.6045, Std Dev = 0.0334\n",
    "# L1LogisticRegression: Mean Accuracy = 0.5511, Std Dev = 0.0596\n",
    "# L2LogisticRegression: Mean Accuracy = 0.5446, Std Dev = 0.0514\n",
    "# ElasticNet: Mean Accuracy = 0.5511, Std Dev = 0.0494\n",
    "# RandomForestClassifier: Mean Accuracy = 0.5691, Std Dev = 0.0683\n",
    "# SupportVectorClassifier: Mean Accuracy = 0.5536, Std Dev = 0.0501"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c3f71",
   "metadata": {},
   "source": [
    "## Second try: test out fewer variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "996b040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 3)\n",
      "Index(['age', 'gender', 'education'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49.66</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45.99</td>\n",
       "      <td>female</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35.38</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42.36</td>\n",
       "      <td>male</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45.14</td>\n",
       "      <td>female</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  gender  education\n",
       "0  49.66    male       18.0\n",
       "1  45.99  female       11.0\n",
       "2  35.38  female       17.0\n",
       "3  42.36    male       18.0\n",
       "4  45.14  female       17.0"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_second = df[['age','gender','education']]\n",
    "X_second = X_second.copy()\n",
    "\n",
    "# binary vars float --> str\n",
    "X_second['gender'] = X_second['gender'].map({1.0: 'male', 0.0: 'female'})\n",
    "\n",
    "print(X_second.shape)\n",
    "print(X_second.columns)\n",
    "X_second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7453ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct preprocesser\n",
    "# decide which encoder to use on each feature\n",
    "onehot_ftrs = ['gender']\n",
    "std_ftrs = ['age','education']\n",
    "\n",
    "# one hot pipeline = just fill nan with 'missing'\n",
    "onehot_transformer = Pipeline(steps=[\n",
    "    ('imputer0', SimpleImputer(strategy='constant', fill_value='missing')), \n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# numeric pipeline with imputation + scaling\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='median')),  # fills missing values with median\n",
    "    ('scaler', StandardScaler())                    # scales features\n",
    "])\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', onehot_transformer, onehot_ftrs), \n",
    "        ('std', numeric_transformer, std_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f13b7c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SimpleLogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 0: 0.5833\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 29: 0.5745\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 58: 0.4222\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 87: 0.6889\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 116: 0.5814\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 145: 0.5000\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 174: 0.5778\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 203: 0.6170\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 1 candidates, totalling 4 fits\n",
      "Best model parameters: {}\n",
      "Test score for random state 261: 0.6304\n",
      "Test Accuracy Scores: [0.5833333333333334, 0.574468085106383, 0.4222222222222222, 0.6888888888888889, 0.5813953488372093, 0.5, 0.5777777777777777, 0.6170212765957447, 0.625, 0.6304347826086957]\n",
      "Mean Test Accuracy: 0.5801\n",
      "Std Dev of Test Accuracy: 0.0701\n",
      "\n",
      "Training L1LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 0: 0.5625\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 29: 0.5745\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 100}\n",
      "Test score for random state 87: 0.6889\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 145: 0.4783\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 174: 0.5778\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 203: 0.6383\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 261: 0.6304\n",
      "Test Accuracy Scores: [0.5625, 0.574468085106383, 0.4444444444444444, 0.6888888888888889, 0.4883720930232558, 0.4782608695652174, 0.5777777777777777, 0.6382978723404256, 0.625, 0.6304347826086957]\n",
      "Mean Test Accuracy: 0.5708\n",
      "Std Dev of Test Accuracy: 0.0751\n",
      "\n",
      "Training L2LogisticRegression...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 0: 0.5625\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 29: 0.5532\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 87: 0.6889\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001}\n",
      "Test score for random state 145: 0.4783\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 174: 0.5778\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 203: 0.6170\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 10}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 6 candidates, totalling 24 fits\n",
      "Best model parameters: {'logisticregression__C': 1}\n",
      "Test score for random state 261: 0.6304\n",
      "Test Accuracy Scores: [0.5625, 0.5531914893617021, 0.4444444444444444, 0.6888888888888889, 0.4883720930232558, 0.4782608695652174, 0.5777777777777777, 0.6170212765957447, 0.625, 0.6304347826086957]\n",
      "Mean Test Accuracy: 0.5666\n",
      "Std Dev of Test Accuracy: 0.0736\n",
      "\n",
      "Training ElasticNet...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 0: 0.5625\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 29: 0.5745\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 87: 0.6889\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 0.001, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 145: 0.4783\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 174: 0.5778\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 203: 0.6170\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 10, 'logisticregression__l1_ratio': 1}\n",
      "Test score for random state 232: 0.6250\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 24 candidates, totalling 96 fits\n",
      "Best model parameters: {'logisticregression__C': 1, 'logisticregression__l1_ratio': 0.001}\n",
      "Test score for random state 261: 0.6304\n",
      "Test Accuracy Scores: [0.5625, 0.574468085106383, 0.4444444444444444, 0.6888888888888889, 0.4883720930232558, 0.4782608695652174, 0.5777777777777777, 0.6170212765957447, 0.625, 0.6304347826086957]\n",
      "Mean Test Accuracy: 0.5687\n",
      "Std Dev of Test Accuracy: 0.0735\n",
      "\n",
      "Training RandomForestClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 0: 0.5833\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 29: 0.5957\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 58: 0.5111\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 1, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 87: 0.6000\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 116: 0.5349\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 145: 0.4130\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.75, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 174: 0.6000\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 5, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 203: 0.5532\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.5, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 232: 0.5833\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 30 candidates, totalling 120 fits\n",
      "Best model parameters: {'randomforestclassifier__max_depth': 3, 'randomforestclassifier__max_features': 0.25, 'randomforestclassifier__n_estimators': 100}\n",
      "Test score for random state 261: 0.5870\n",
      "Test Accuracy Scores: [0.5833333333333334, 0.5957446808510638, 0.5111111111111111, 0.6, 0.5348837209302325, 0.41304347826086957, 0.6, 0.5531914893617021, 0.5833333333333334, 0.5869565217391305]\n",
      "Mean Test Accuracy: 0.5562\n",
      "Std Dev of Test Accuracy: 0.0555\n",
      "\n",
      "Training SupportVectorClassifier...\n",
      "---Running random state 0---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 10.0}\n",
      "Test score for random state 0: 0.4792\n",
      "---Running random state 29---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1.0, 'svc__gamma': 10.0}\n",
      "Test score for random state 29: 0.4894\n",
      "---Running random state 58---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 100000.0}\n",
      "Test score for random state 58: 0.4444\n",
      "---Running random state 87---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 100.0, 'svc__gamma': 10.0}\n",
      "Test score for random state 87: 0.6222\n",
      "---Running random state 116---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 0.01, 'svc__gamma': 1e-05}\n",
      "Test score for random state 116: 0.4884\n",
      "---Running random state 145---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 10.0}\n",
      "Test score for random state 145: 0.5435\n",
      "---Running random state 174---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 1000.0}\n",
      "Test score for random state 174: 0.5333\n",
      "---Running random state 203---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 1000.0, 'svc__gamma': 1000.0}\n",
      "Test score for random state 203: 0.4043\n",
      "---Running random state 232---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 10.0, 'svc__gamma': 10.0}\n",
      "Test score for random state 232: 0.5833\n",
      "---Running random state 261---\n",
      "Fitting 4 folds for each of 36 candidates, totalling 144 fits\n",
      "Best model parameters: {'svc__C': 0.01, 'svc__gamma': 1e-05}\n",
      "Test score for random state 261: 0.6304\n",
      "Test Accuracy Scores: [0.4791666666666667, 0.48936170212765956, 0.4444444444444444, 0.6222222222222222, 0.4883720930232558, 0.5434782608695652, 0.5333333333333333, 0.40425531914893614, 0.5833333333333334, 0.6304347826086957]\n",
      "Mean Test Accuracy: 0.5218\n",
      "Std Dev of Test Accuracy: 0.0708\n",
      "\n",
      "Summary of Results:\n",
      "SimpleLogisticRegression: Mean Accuracy = 0.5801, Std Dev = 0.0701\n",
      "L1LogisticRegression: Mean Accuracy = 0.5708, Std Dev = 0.0751\n",
      "L2LogisticRegression: Mean Accuracy = 0.5666, Std Dev = 0.0736\n",
      "ElasticNet: Mean Accuracy = 0.5687, Std Dev = 0.0735\n",
      "RandomForestClassifier: Mean Accuracy = 0.5562, Std Dev = 0.0555\n",
      "SupportVectorClassifier: Mean Accuracy = 0.5218, Std Dev = 0.0708\n"
     ]
    }
   ],
   "source": [
    "# evaluation metric = accuracy\n",
    "summary_acc = {}\n",
    "for model_name, (algo, param_grid) in models.items():\n",
    "    print(f\"\\nTraining {model_name}...\")\n",
    "    test_scores, best_models = MLpipe_SGKFold(X_few_missing, y, participants_ids, preprocessor, algo, param_grid, model_name, \"accuracy\")\n",
    "    mean_score = np.mean(test_scores)\n",
    "    stddev_score = np.std(test_scores)\n",
    "    print(\"Test Accuracy Scores:\", test_scores)\n",
    "    print(f\"Mean Test Accuracy: {mean_score:.4f}\")\n",
    "    print(f\"Std Dev of Test Accuracy: {stddev_score:.4f}\")\n",
    "    summary_acc[model_name] = (mean_score, stddev_score)\n",
    "\n",
    "# display the summary\n",
    "print(\"\\nSummary of Results:\")\n",
    "for model_name, (mean_score, stddev_score) in summary_acc.items():\n",
    "    print(f\"{model_name}: Mean Accuracy = {mean_score:.4f}, Std Dev = {stddev_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3bca2ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of Results:\n",
    "# SimpleLogisticRegression: Mean Accuracy = 0.5801, Std Dev = 0.0701\n",
    "# L1LogisticRegression: Mean Accuracy = 0.5708, Std Dev = 0.0751\n",
    "# L2LogisticRegression: Mean Accuracy = 0.5666, Std Dev = 0.0736\n",
    "# ElasticNet: Mean Accuracy = 0.5687, Std Dev = 0.0735\n",
    "# RandomForestClassifier: Mean Accuracy = 0.5562, Std Dev = 0.0555\n",
    "# SupportVectorClassifier: Mean Accuracy = 0.5218, Std Dev = 0.0708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "10dc9071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer0&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;]),\n",
       "                                                 (&#x27;std&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer2&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;education&#x27;])])),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000000, solver=&#x27;saga&#x27;))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;Pipeline<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.pipeline.Pipeline.html\">?<span>Documentation for Pipeline</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>Pipeline(steps=[(&#x27;columntransformer&#x27;,\n",
       "                 ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer0&#x27;,\n",
       "                                                                   SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                                 strategy=&#x27;constant&#x27;)),\n",
       "                                                                  (&#x27;onehot&#x27;,\n",
       "                                                                   OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  [&#x27;gender&#x27;]),\n",
       "                                                 (&#x27;std&#x27;,\n",
       "                                                  Pipeline(steps=[(&#x27;imputer2&#x27;,\n",
       "                                                                   SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                                  (&#x27;scaler&#x27;,\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  [&#x27;age&#x27;, &#x27;education&#x27;])])),\n",
       "                (&#x27;logisticregression&#x27;,\n",
       "                 LogisticRegression(max_iter=1000000, solver=&#x27;saga&#x27;))])</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;columntransformer: ColumnTransformer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.compose.ColumnTransformer.html\">?<span>Documentation for columntransformer: ColumnTransformer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>ColumnTransformer(transformers=[(&#x27;onehot&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer0&#x27;,\n",
       "                                                  SimpleImputer(fill_value=&#x27;missing&#x27;,\n",
       "                                                                strategy=&#x27;constant&#x27;)),\n",
       "                                                 (&#x27;onehot&#x27;,\n",
       "                                                  OneHotEncoder(handle_unknown=&#x27;ignore&#x27;,\n",
       "                                                                sparse_output=False))]),\n",
       "                                 [&#x27;gender&#x27;]),\n",
       "                                (&#x27;std&#x27;,\n",
       "                                 Pipeline(steps=[(&#x27;imputer2&#x27;,\n",
       "                                                  SimpleImputer(strategy=&#x27;median&#x27;)),\n",
       "                                                 (&#x27;scaler&#x27;, StandardScaler())]),\n",
       "                                 [&#x27;age&#x27;, &#x27;education&#x27;])])</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">onehot</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;gender&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(fill_value=&#x27;missing&#x27;, strategy=&#x27;constant&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;OneHotEncoder<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.OneHotEncoder.html\">?<span>Documentation for OneHotEncoder</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>OneHotEncoder(handle_unknown=&#x27;ignore&#x27;, sparse_output=False)</pre></div> </div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">std</label><div class=\"sk-toggleable__content fitted\"><pre>[&#x27;age&#x27;, &#x27;education&#x27;]</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;SimpleImputer<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.impute.SimpleImputer.html\">?<span>Documentation for SimpleImputer</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>SimpleImputer(strategy=&#x27;median&#x27;)</pre></div> </div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;StandardScaler<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.preprocessing.StandardScaler.html\">?<span>Documentation for StandardScaler</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>StandardScaler()</pre></div> </div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(max_iter=1000000, solver=&#x27;saga&#x27;)</pre></div> </div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('columntransformer',\n",
       "                 ColumnTransformer(transformers=[('onehot',\n",
       "                                                  Pipeline(steps=[('imputer0',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('onehot',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
       "                                                                                 sparse_output=False))]),\n",
       "                                                  ['gender']),\n",
       "                                                 ('std',\n",
       "                                                  Pipeline(steps=[('imputer2',\n",
       "                                                                   SimpleImputer(strategy='median')),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['age', 'education'])])),\n",
       "                ('logisticregression',\n",
       "                 LogisticRegression(max_iter=1000000, solver='saga'))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open('../results/SimpleLogisticRegression_accuracy_remitter.save', 'rb')\n",
    "best_models, test_scores = pickle.load(file)\n",
    "file.close()\n",
    "\n",
    "# get best model\n",
    "top_one_index = np.argsort(test_scores)[-1:][0]  \n",
    "best_model = best_models[top_one_index]\n",
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd3e3b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(max_iter=1000000, solver='saga')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "log_reg_model = best_model.named_steps['logisticregression']\n",
    "print(log_reg_model)\n",
    "\n",
    "# get the preprocessed feature names\n",
    "preprocessor = best_model.named_steps['columntransformer']\n",
    "onehot_columns = preprocessor.named_transformers_['onehot'].get_feature_names_out()\n",
    "numeric_columns = std_ftrs\n",
    "feature_names = np.concatenate([onehot_columns, numeric_columns])\n",
    "\n",
    "# get coefficients\n",
    "coefs = log_reg_model.coef_[0]  # binary classification\n",
    "\n",
    "# Put in dataframe\n",
    "feat_imp = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': np.abs(coefs),\n",
    "    'coef': coefs\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.barh(feat_imp['feature'], feat_imp['importance'])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel('Coefficient magnitude (importance)')\n",
    "plt.title('Feature Importance for Logistic Regression')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b9e65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
