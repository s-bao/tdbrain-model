{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "239e1f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_rows = 1000\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GroupKFold, GroupShuffleSplit, GridSearchCV, StratifiedKFold, train_test_split\n",
    "from sklearn.model_selection import permutation_test_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bbdef7",
   "metadata": {},
   "source": [
    "## Target: Remitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7727d48f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_ID</th>\n",
       "      <th>DISC/REP</th>\n",
       "      <th>indication</th>\n",
       "      <th>formal_status</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Consent</th>\n",
       "      <th>sessSeason</th>\n",
       "      <th>sessTime</th>\n",
       "      <th>Responder</th>\n",
       "      <th>Remitter</th>\n",
       "      <th>...</th>\n",
       "      <th>ever_used_cigarette</th>\n",
       "      <th>hours_since_last_cigarette</th>\n",
       "      <th>ever_used_coffee</th>\n",
       "      <th>hours_since_last_coffee</th>\n",
       "      <th>ever_used_beer</th>\n",
       "      <th>hours_since_last_beer</th>\n",
       "      <th>ever_used_drugs</th>\n",
       "      <th>hours_since_last_drugs</th>\n",
       "      <th>hours_since_last_meal</th>\n",
       "      <th>hours_since_last_sleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sub-87999321</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>spring</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sub-88000181</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sub-88000313</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sub-88000489</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sub-88000533</td>\n",
       "      <td>DISCOVERY</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD</td>\n",
       "      <td>MDD-rTMS</td>\n",
       "      <td>YES</td>\n",
       "      <td>summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  participants_ID   DISC/REP indication formal_status   Dataset Consent  \\\n",
       "0    sub-87999321  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "1    sub-88000181  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "2    sub-88000313  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "3    sub-88000489  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "4    sub-88000533  DISCOVERY        MDD           MDD  MDD-rTMS     YES   \n",
       "\n",
       "  sessSeason sessTime  Responder  Remitter  ...  ever_used_cigarette  \\\n",
       "0     spring      NaN          1         1  ...                  0.0   \n",
       "1     summer      NaN          0         0  ...                  0.0   \n",
       "2     summer      NaN          1         1  ...                  1.0   \n",
       "3     summer      NaN          1         1  ...                  0.0   \n",
       "4     summer      NaN          1         1  ...                  1.0   \n",
       "\n",
       "   hours_since_last_cigarette  ever_used_coffee  hours_since_last_coffee  \\\n",
       "0                         NaN               0.0                      NaN   \n",
       "1                         NaN               1.0                      9.0   \n",
       "2                         9.0               1.0                      9.0   \n",
       "3                         NaN               1.0                      5.0   \n",
       "4                         8.0               1.0                      9.0   \n",
       "\n",
       "   ever_used_beer  hours_since_last_beer  ever_used_drugs  \\\n",
       "0             0.0                    NaN              1.0   \n",
       "1             1.0                   15.0              1.0   \n",
       "2             0.0                    NaN              1.0   \n",
       "3             1.0                   13.0              1.0   \n",
       "4             1.0                   13.0              1.0   \n",
       "\n",
       "   hours_since_last_drugs  hours_since_last_meal  hours_since_last_sleep  \n",
       "0                     0.0                    5.0                     7.0  \n",
       "1                     0.0                    3.0                     7.0  \n",
       "2                     0.0                    3.0                     9.0  \n",
       "3                     0.0                    5.0                     9.0  \n",
       "4                     0.0                    3.0                     5.0  \n",
       "\n",
       "[5 rows x 114 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/final_dataset_remitter.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c77ec077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All data shape: (226, 114)\n",
      "Only MDD data shape: (132, 114)\n"
     ]
    }
   ],
   "source": [
    "# pull out rows where Dataset = MDD-rTMS\n",
    "print(\"All data shape:\", df.shape)\n",
    "df = df[df['Dataset'] == 'MDD-rTMS']\n",
    "print(\"Only MDD data shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e6182e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "participants_ID                 0\n",
      "BDI_pre                         0\n",
      "BDI_post                        0\n",
      "n_oddb_FN                       0\n",
      "n_oddb_CN                       0\n",
      "n_oddb_FP                       0\n",
      "EO                              0\n",
      "EC                              0\n",
      "nrSessions                      0\n",
      "gender                          0\n",
      "sessID                          0\n",
      "Remitter                        0\n",
      "Responder                       0\n",
      "n_oddb_CP                       0\n",
      "sessSeason                      0\n",
      "Consent                         0\n",
      "Dataset                         0\n",
      "formal_status                   0\n",
      "indication                      0\n",
      "DISC/REP                        0\n",
      "age                             0\n",
      "n_wm_CN                         1\n",
      "n_wm_CP                         1\n",
      "n_wm_FP                         1\n",
      "n_wm_FN                         1\n",
      "ever_used_coffee                1\n",
      "well                            1\n",
      "vision                          1\n",
      "hearing                         1\n",
      "rTMS_protocol                   1\n",
      "ever_used_cigarette             1\n",
      "avg_rt_oddb_CP                  1\n",
      "ever_used_beer                  1\n",
      "ever_used_drugs                 1\n",
      "education                       1\n",
      "hours_since_last_meal           1\n",
      "hours_since_last_sleep          1\n",
      "neoFFI_q22                      4\n",
      "neoFFI_q54                      4\n",
      "neoFFI_q55                      4\n",
      "neoFFI_q56                      4\n",
      "neoFFI_q57                      4\n",
      "neoFFI_q58                      4\n",
      "neoFFI_q59                      4\n",
      "neoFFI_q21                      4\n",
      "neoFFI_q19                      4\n",
      "neoFFI_q18                      4\n",
      "neoFFI_q17                      4\n",
      "neoFFI_q16                      4\n",
      "neoFFI_q15                      4\n",
      "neoFFI_q53                      4\n",
      "neoFFI_q14                      4\n",
      "neoFFI_q12                      4\n",
      "neoFFI_q11                      4\n",
      "neoFFI_q10                      4\n",
      "neoFFI_q9                       4\n",
      "neoFFI_q8                       4\n",
      "neoFFI_q7                       4\n",
      "neoFFI_q6                       4\n",
      "neoFFI_q5                       4\n",
      "neoFFI_q4                       4\n",
      "neoFFI_q3                       4\n",
      "neoFFI_q2                       4\n",
      "neoFFI_q1                       4\n",
      "neoFFI_q13                      4\n",
      "neoFFI_q52                      4\n",
      "neoFFI_q60                      4\n",
      "neoFFI_q50                      4\n",
      "neoFFI_q23                      4\n",
      "neoFFI_q24                      4\n",
      "neoFFI_q25                      4\n",
      "neoFFI_q26                      4\n",
      "neoFFI_q27                      4\n",
      "neoFFI_q28                      4\n",
      "neoFFI_q29                      4\n",
      "neoFFI_q51                      4\n",
      "neoFFI_q31                      4\n",
      "neoFFI_q32                      4\n",
      "neoFFI_q33                      4\n",
      "neoFFI_q34                      4\n",
      "neoFFI_q35                      4\n",
      "neoFFI_q36                      4\n",
      "neoFFI_q30                      4\n",
      "neoFFI_q41                      4\n",
      "neoFFI_q48                      4\n",
      "neoFFI_q49                      4\n",
      "neoFFI_q46                      4\n",
      "neoFFI_q45                      4\n",
      "neoFFI_q44                      4\n",
      "neoFFI_q43                      4\n",
      "neoFFI_q47                      4\n",
      "neoFFI_q20                      4\n",
      "neoFFI_q40                      4\n",
      "neoFFI_q39                      4\n",
      "neoFFI_q38                      4\n",
      "neoFFI_q37                      4\n",
      "neoFFI_q42                      4\n",
      "hours_since_last_coffee        25\n",
      "avg_rt_oddb_FP                 70\n",
      "hours_since_last_drugs         81\n",
      "hours_since_last_cigarette     84\n",
      "hours_since_last_beer          86\n",
      "sessTime                      131\n",
      "avg_rt_wm_FP                  132\n",
      "YBOCS_pre                     132\n",
      "NF_protocol                   132\n",
      "ADHD_post_Hyp_leading         132\n",
      "ADHD_post_Att_leading         132\n",
      "avg_rt_wm_CP                  132\n",
      "ADHD_pre_Hyp_leading          132\n",
      "height                        132\n",
      "weight                        132\n",
      "YBOCS_post                    132\n",
      "ADHD_pre_Att_leading          132\n",
      "dtype: int64\n",
      "Row missing hearing: Index([45], dtype='int64')\n",
      "Row missing well: Index([45], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "missing_counts = df.isnull().sum()\n",
    "missing_counts_sorted = missing_counts.sort_values() # sort\n",
    "print(missing_counts_sorted)\n",
    "\n",
    "print(\"Row missing hearing:\", df[df[\"hearing\"].isna()].index)\n",
    "print(\"Row missing well:\", df[df[\"well\"].isna()].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0e7e0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after keeping only first entry for each participant: (124, 114)\n"
     ]
    }
   ],
   "source": [
    "duplicate_ids = df[\"participants_ID\"].value_counts()\n",
    "duplicate_ids = duplicate_ids[duplicate_ids > 1].index\n",
    "\n",
    "# print(df[df[\"participants_ID\"].isin(duplicate_ids)])\n",
    "# noticed that some participants have multiple sessions of data, so we decided\n",
    "# to only keep the first entry for each participant\n",
    "\n",
    "df = df.drop_duplicates(subset=\"participants_ID\", keep=\"first\")\n",
    "print(\"Shape after keeping only first entry for each participant:\", df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9c3f71",
   "metadata": {},
   "source": [
    "### Model & Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "996b040c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 5)\n",
      "Index(['age', 'gender', 'education', 'BDI_pre', 'ever_used_drugs'], dtype='object')\n",
      "age                float64\n",
      "gender              object\n",
      "education          float64\n",
      "BDI_pre            float64\n",
      "ever_used_drugs    float64\n",
      "dtype: object\n",
      "     age  gender  education  BDI_pre  ever_used_drugs\n",
      "0  49.66    male       18.0     20.0              1.0\n",
      "1  45.99  female       11.0     47.0              1.0\n",
      "2  35.38  female       17.0     21.0              1.0\n",
      "3  42.36    male       18.0     21.0              1.0\n",
      "4  45.14  female       17.0     42.0              1.0\n"
     ]
    }
   ],
   "source": [
    "X = df[['age', 'gender', 'education', 'BDI_pre', 'ever_used_drugs']]\n",
    "y = df['Remitter']\n",
    "\n",
    "# binary vars float --> str\n",
    "X = X.copy()\n",
    "X['gender'] = X['gender'].map({1.0: 'male', 0.0: 'female'})\n",
    "\n",
    "print(X.shape)\n",
    "print(X.columns)\n",
    "print(X.dtypes)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7453ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct preprocesser\n",
    "# decide which encoder to use on each feature\n",
    "onehot_ftrs = ['gender', 'ever_used_drugs']\n",
    "std_ftrs = ['age', 'education', 'BDI_pre']\n",
    "\n",
    "# one hot pipeline\n",
    "X['ever_used_drugs'] = X['ever_used_drugs'].fillna(99)\n",
    "onehot_transformer = Pipeline(steps=[\n",
    "    ('imputer0', SimpleImputer(strategy='constant')), \n",
    "    ('onehot', OneHotEncoder(sparse_output=False, handle_unknown='ignore')),\n",
    "])\n",
    "\n",
    "# numeric pipeline with imputation + scaling\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer2', SimpleImputer(strategy='median')),  # fills missing values with median\n",
    "    ('scaler', StandardScaler())                     # scales features\n",
    "])\n",
    "\n",
    "# collect all the encoders\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', onehot_transformer, onehot_ftrs), \n",
    "        ('std', numeric_transformer, std_ftrs)])\n",
    "\n",
    "clf = Pipeline(steps=[('preprocessor', preprocessor)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce4f650c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 5)\n",
      "(25, 5)\n",
      "Fold 1\n",
      "X_train shape: (74, 5)\n",
      "X_val shape: (25, 5)\n",
      "Fold 2\n",
      "X_train shape: (74, 5)\n",
      "X_val shape: (25, 5)\n",
      "Fold 3\n",
      "X_train shape: (74, 5)\n",
      "X_val shape: (25, 5)\n",
      "Fold 4\n",
      "X_train shape: (75, 5)\n",
      "X_val shape: (24, 5)\n"
     ]
    }
   ],
   "source": [
    "# outer split: stratified split test and other\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42) \n",
    "\n",
    "print(X_train_val.shape)\n",
    "print(X_test.shape)\n",
    "\n",
    "# inner split: stratified k fold with k = 4 (60-20-20)\n",
    "inner_split = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(inner_split.split(X_train_val, y_train_val)):\n",
    "    print(f\"Fold {fold+1}\")\n",
    "    X_train, X_val = X_train_val.iloc[train_idx], X_train_val.iloc[val_idx]\n",
    "    y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    print(\"X_train shape:\", X_train.shape)\n",
    "    print(\"X_val shape:\", X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78994cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before preprocessing...\n",
      "X train: (75, 5)\n",
      "X val: (24, 5)\n",
      "X test: (25, 5) \n",
      "\n",
      "['gender_female', 'gender_male', 'ever_used_drugs_0.0', 'ever_used_drugs_1.0', 'age', 'education', 'BDI_pre']\n",
      "After preprocessing...\n",
      "X train: (75, 7)\n",
      "X val: (24, 7)\n",
      "X test: (25, 7)\n"
     ]
    }
   ],
   "source": [
    "# try preprocessor on the last fold\n",
    "print(\"Before preprocessing...\")\n",
    "print(\"X train:\", X_train.shape)\n",
    "print(\"X val:\", X_val.shape)\n",
    "print(\"X test:\", X_test.shape, \"\\n\")\n",
    "\n",
    "X_train_prep = clf.fit_transform(X_train)\n",
    "\n",
    "# relabel the columns after transformation\n",
    "onehot_feature_names = clf.named_steps['preprocessor'].named_transformers_['onehot'].get_feature_names_out()\n",
    "new_feature_names = list(onehot_feature_names) + std_ftrs\n",
    "print(new_feature_names)\n",
    "\n",
    "X_train_prep = pd.DataFrame(X_train_prep, columns=new_feature_names)\n",
    "X_val_prep = pd.DataFrame(clf.transform(X_val), columns=new_feature_names)\n",
    "X_test_prep = pd.DataFrame(clf.transform(X_test), columns=new_feature_names)\n",
    "\n",
    "# print number of data points after preprocessing\n",
    "print(\"After preprocessing...\")\n",
    "print(\"X train:\", X_train_prep.shape)\n",
    "print(\"X val:\", X_val_prep.shape)\n",
    "print(\"X test:\", X_test_prep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cdd16b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on validation set: 0.5\n",
      "Accuracy on training set: 0.6133333333333333\n"
     ]
    }
   ],
   "source": [
    "# try simple model on data\n",
    "log_reg = LogisticRegression(solver='saga', max_iter=100000000)\n",
    "log_reg.fit(X_train_prep, y_train)\n",
    "y_pred_val = log_reg.predict(X_val_prep)\n",
    "y_pred_train = log_reg.predict(X_train_prep)\n",
    "print(\"Accuracy on validation set:\", accuracy_score(y_val,y_pred_val))\n",
    "print(\"Accuracy on training set:\", accuracy_score(y_train,y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c95d092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV accuracy: 0.6270833333333333\n",
      "p-value: 0.017982017982017984\n"
     ]
    }
   ],
   "source": [
    "# test out permutation_test_score function\n",
    "log_reg = LogisticRegression(solver='saga', max_iter=100000000)\n",
    "pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', log_reg)\n",
    "])\n",
    "\n",
    "score, perm_scores, p_value = permutation_test_score(\n",
    "    pipe, \n",
    "    X_train_val, \n",
    "    y_train_val, \n",
    "    scoring=\"accuracy\", \n",
    "    cv=inner_split,\n",
    "    n_permutations=1000,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"CV accuracy:\", score)\n",
    "print(\"p-value:\", p_value)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
